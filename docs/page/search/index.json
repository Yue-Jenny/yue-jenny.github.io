[{"content":"Replication And Sharding 前言 Replication 目的是建立一個高可用的資料庫架構 可以選擇同步或非同步的方式進行 main 與 replication 資料庫的同步方式 Sharding 目的是為了建立高吞吐量的資料庫架構 達成 sharding 的策略有 hashing strategy 使用不同 table (需要確認資料夠 unitform) 存取 參考資料 👐 system experts 🍀 若喜歡我的分享，可以幫我拍拍手👏，是對我最大的鼓勵\n","date":"2023-02-14T15:00:24+08:00","permalink":"https://yue-jenny.github.io/2023/02/%E7%B3%BB%E7%B5%B1%E8%A8%AD%E8%A8%88%E5%9F%BA%E7%A4%8E%E7%AD%86%E8%A8%98%E5%8D%81-replication-and-sharding/","title":"系統設計基礎筆記(十) Replication And Sharding"},{"content":"Peer-To-Peer Networks P2P network 介紹 對等式網路，又稱對等技術，依靠使用者群（peers）交換資訊的網際網路體系 目標就是讓所有的客戶端都能提供資源，包括頻寬，儲存空間和計算能力。因此，當有節點加入且對系統請求增多，整個系統的容量也增大。這是具有一組固定伺服器的Client-Server結構不能實現的，因為在上述這種結構中，客戶端的增加意味著所有使用者更慢的資料傳輸。 根據中央化程度，可以區分為一般型P2P、特殊型P2P與混合型P2P，使用一般型P2P技術的網路系統有比特幣、Gnutella或自由網等。 好處 不會因為單點故障就導致整體服務無法運作 不會讓單點遇到效能瓶頸 Gossip Protocol 簡介 又稱作 epidemic protocol，是 P2P network 的核心技術 Gossip protocol 的實際應用如 Cassandra / Redis Cluster / Consul 等集群架構 consul 用於管理 membership 與傳播消息，有興趣可點這邊 廣度優先遍歷(Breadth-First Search, BFS) 假設 A 得到某些資訊，更新了自身的資訊，A 需要將資訊告訴 B、C 等，然後 B、C 告訴其他的 D、E、F、G，一直遍歷。如果節點 B 收到 A 的消息，發現自己早就知道這個消息就直接忽略，從而可以防止圖重複遍歷。 執行過程 Gossip 過程是異步的，也就是說發消息的節點不會關注對方是否收到，即不等待響應；不管對方有沒有收到，它都會每隔1 秒向周圍節點發消息 通信模式 Push: 節點 A 將數據 (key,value,version) 及對應的版本號推送給節點 B，節點 B 更新 A 中比自己新的數據 Pull: A 僅將數據 key, version 推送給 B，B 將本地比 A 新的數據（Key, value, version）推送給 A，A 更新本地 對 A 來說是 pull Push/Pull: 與 Pull 類似，步驟上多一步，A 再將本地比 B 新的數據推送給 B，B 則更新本地 收斂速度最快，收斂速度是指所有節點的資訊達到一致的速度 優點 擴展性 (scalability) 允許任意節點的增加和減少 容錯 (Fault tolerance) 任何節點的故障和重啟都不會影響 Gossip 消息的傳播 去中心化 (decentralization) 所有節點都可以是對等的，任何一個節點無需知道整個狀況，只要網路相通，任意一個節點就可以把消息散播到全網 一致性收斂 消息會以一傳十、十傳百一樣的指數級速度在網路中快速傳播，因此系統狀態的不一致可以在很快的時間內收斂到一致 簡易實現 缺點 latency 節點只會隨機向少數幾個節點發送消息，消息最終是通過多個輪次的散播而到達全網 消息冗餘 節點會定期隨機選擇周圍節點發送消息，而收到消息的節點也會重複該步驟，因此就不可避免的存在消息重複發送給同一節點的情況，造成了消息的冗餘，同時也增加了收到消息的節點的處理壓力。 由於是定期發送，即使收到了消息的節點還會反複收到重複消息，加重了消息的冗餘。 參考資料 👐 對等網路 - 维基百科，自由的百科全书 Day20|P2P網路(1)：P2P網路基礎知識 - iT 邦幫忙::一起幫忙解決難題，拯救 IT 人的一天 Gossip Protocol 介紹 (上) - 從 Cassandra 內部實作認識 Gossip Protocol 的使用 P2P 网络核心技术：Gossip 协议 🍀 若喜歡我的分享，可以幫我拍拍手👏，是對我最大的鼓勵\n","date":"2023-02-10T09:58:46+08:00","permalink":"https://yue-jenny.github.io/2023/02/%E7%B3%BB%E7%B5%B1%E8%A8%AD%E8%A8%88%E5%9F%BA%E7%A4%8E%E7%AD%86%E8%A8%98%E4%B9%9D-peer-to-peer-networks/","title":"系統設計基礎筆記(九) Peer-To-Peer Networks"},{"content":"Pulling And Streaming Prerequistites Client-Server Model client 發 request，server 提供資料或服務給 client Socket 是一種一種網路傳輸協定，實現 client 與 server 的雙向溝通機制，使用 TCP 連線，透過 HTTP 3-way handshake 建立連線 目的是可以即時地讓雙方交換資訊，應用場景如聊天室 優點是較少開銷、即時性、二進位支援等 Polling 每隔多少固定的時間去更新資料 Streaming (Pushing) 持續與 server 保持連線，並隨時取得最新資料 參考資料 👐 WebSocket - Web APIs | MDN Polling and Streaming - Concept \u0026amp; Scenarios - GeeksforGeeks 🍀 若喜歡我的分享，可以幫我拍拍手👏，是對我最大的鼓勵\n","date":"2023-02-06T23:24:44+08:00","permalink":"https://yue-jenny.github.io/2023/02/%E7%B3%BB%E7%B5%B1%E8%A8%AD%E8%A8%88%E5%9F%BA%E7%A4%8E%E7%AD%86%E8%A8%98%E5%85%AB-pulling-and-streaming/","title":"系統設計基礎筆記(八) Pulling And Streaming"},{"content":"Configuration Static Configuration V.S Dynamic Configuration Static Configuration 以 YAML 或 JSON 為主的設定檔\nYAML: --- receipt: Oz-Ware Purchase Invoice date: 2012-08-06 customer: given: Dorothy family: Gale JSON { \u0026#34;streetAddress\u0026#34;: \u0026#34;21 2nd Street\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;New York\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;NY\u0026#34;, \u0026#34;postalCode\u0026#34;: \u0026#34;10021\u0026#34; } 需要跟 source code 結合\n需要 re-deploy 應用才能更新設定\nDynamic Configuration UI 介面去控制設定 需要去實作此 feature 參考資料 👐 🍀 若喜歡我的分享，可以幫我拍拍手👏，是對我最大的鼓勵\n","date":"2023-02-04T10:30:09+08:00","permalink":"https://yue-jenny.github.io/2023/02/%E7%B3%BB%E7%B5%B1%E8%A8%AD%E8%A8%88%E5%9F%BA%E7%A4%8E%E7%AD%86%E8%A8%98%E4%B8%83-configuration/","title":"系統設計基礎筆記(七) Configuration"},{"content":"Rate Limiting Prerequistites DDOS 分散式阻斷服務攻擊（distributed denial-of-service attack）亦稱洪水攻擊 DoS 阻斷服務攻擊（英語：denial-of-service attack） 預防方式是使用 rate limit, 可以限制 IP, 使用者帳戶, 區域等等。 Rate Limiting 意思就是限流 根據維基百科，定義是「控制計算機發送或接收的請求之頻率」 Rate Limiting for Multiple Server use Redis to implement rate limiting for multiple servers Application Layer 如何實現 Rate Limit 實現方式 在 Node.js 裡，有一個用來做限流的 express middleware 叫做 express-rate-limit，可看這篇 缺點 在 API server 裡面自己用 middleware 做限流，雖然這樣做感覺很方便，但也會讓 API server 無法完全專注在業務邏輯上 AWS WAF (Web Application Firewall) 目的是保護您的 Web 應用程式免受常見 Web 入侵程式的危害 運作方式 關於 AWS WAF components Web ACLs\n目的是保護 AWS resources，藉由建立一組 web ACL 並新增 rules 去定義保護策略 屬於 AWS WAF resource Rules\n顧名思義，定義檢查標準 (inspection criteria)，當有 matching requests，可以做的事情如允許通過、計算他們或者執行 CAPTCHA puzzles 去檢查是否為機器人 不屬於 AWS WAF resource Rule groups\n可以組合自己的 rule groups，也可以直接在 web ACL 中定義規則 屬於 AWS WAF resource 關於 Web ACL capacity units (WCU) 使用 WCU 來計算與控制運行規則、規則組和 Web ACL 所需的操作資源 For example, a size constraint rule statement uses fewer WCUs than a statement that inspects against a regex pattern set. AWS WAF 會管理 Rule capacity, Rule group capacity, Web ACL capacity，詳情可以參考這篇 關於 Resources that you can protect with AWS WAF 使用 AWS WAF web ACL 去保護全球或區域性的 resource types，只需要將 web ACL 連結到你想要保護的 resources 上，官方提供 Amazon CloudFront 以及 Regional resources 特別說明 Note: Amazon CloudFront 是一項內容交付網路(CDN) 服務，可協助您以高速效能、安全和開發人員易用性快速、可靠地分發靜態和動態內容。 限制 一個 web ACL 可以連結多個 AWS resources，一個 AWS resource 僅連結一個 web ACL 一個 web ACL 可以連結多個 CloudFront distributions，且已連結到 CloudFront distribution 的 web ACL 不能再去連結其他 AWS resource type 使用情境，舉例 3 點 篩選 Web 流量 建立規則以根據各種條件篩選 Web 請求，例如 IP 地址、HTTP 標頭和內文，或自訂 URI。 防止帳戶接管詐騙 監控應用程式的登入頁面，偵測以盜用憑證對使用者帳戶進行的未經授權存取。 使用 API 管理 AWS WAF 自動建立和維護規則，並將這些規則併入開發和設計程序中。 比較 AWS WAF, AWS Shield 與 AWS Firewall Manager AWS WAF monitor requests that are forwarded to your web applications and control access to your content. AWS Shield help protect against DDoS attacks. AWS Firewall Manager set up your firewall rules and apply the rules automatically across accounts and resources, even as new resources are added. 參考資料 👐 What are AWS WAF, AWS Shield, and AWS Firewall Manager? How AWS WAF works 低延遲內容交付網路 (CDN) - Amazon CloudFront - Amazon Web Services express-rate-limit 🍀 若喜歡我的分享，可以幫我拍拍手👏，是對我最大的鼓勵\n","date":"2023-02-02T10:55:49+08:00","permalink":"https://yue-jenny.github.io/2023/02/%E7%B3%BB%E7%B5%B1%E8%A8%AD%E8%A8%88%E5%9F%BA%E7%A4%8E%E7%AD%86%E8%A8%98%E5%85%AD-rate-limiting/","title":"系統設計基礎筆記(六) Rate Limiting"},{"content":"Logging And Monitoring 前言 Prerequistites Logging Monitoring Alerting Elastic Search, Logstash, Kibana (ELK) Elasticsearch 的核心是搜索引擎、採集管道Logstash 和可視化工具Kibana。\nElastic Search Introduce 一個建置在 Apache Lucene 上的分散式搜尋和分析引擎，提供 near real-time 的數據搜尋與分析，能夠儲存複雜結構的數據\n授權不是開放原始碼，也不向使用者提供相同的自由。因此引進了 OpenSearch 專案，此專案是一個社群驅動型 ALv2 許可的開放原始碼 Elasticsearch 和 Kibana 分支\n列舉幾項應用場景:\n網站或應用的 search box 儲存與分析 logs, metrics 等 structured 或 unstructured 文字進而找出安全漏洞 將 Elasticsearch 作為儲存引擎去自動化 workflows 將 Elasticsearch 作為 GIS 去整合與分析空間資料 將 Elasticsearch 作為生物訊息搜尋工具去儲存與處理基因資料 以資料流來簡易說明 Elasticsearch 8.6(current) 做的事情 documents and indices\n儲存已序列化為 JSON 文檔的複雜數據結構 有多個 Elasticsearch 節點時，存儲的文檔分佈在集群中，並且可以從任何節點立即訪問 支援快速搜尋，因為使用了 “inverted index” 的數據結構，每種數據都有專屬並優化過的結構，如 text fields are stored in inverted indices numeric and geo fields are stored in BKD trees 支援 schema-less，當不確定如何處理文檔中的字段時使用，需啟用 “dynamic mapping” search and analyze\n支援 structured queries, full text queries 以及結合兩種搜尋方式 除此之外，也有支援高性能地理空間與數值數據搜尋 透過 Elasticsearch’s comprehensive JSON-style query language (Query DSL) 可以去訪問這些搜尋功能 結合 JDBC 與 ODBC drivers 可以讓第三方 applications 更加廣泛地透過 SQL 與 Elasticsearch 互動 scalabilty and resilience\nElasticsearch 可根據您的需求進行擴展，並且知道如何平衡多節點 cluster 運作方式 將 shards 分布到多個 nodes 上，利用確保冗餘 (redundancy) 可以達到防止 hardware failures 以及增加 query capacity (讀取請求的能力)，當 nodes 數量增減，Elasticsearch 會自動遷移 shard 以重新平衡集群 shard 有兩種 types primaries: Each document in an index belongs to one primary shard. 數量固定。 replicas: a copy of a primary shard. 為了冗餘 (redundancy)，可以達到防止 hardware failures 以及增加 query capacity (讀取請求的能力)。 數量可以更改。 Logstash Introduce 一種開放原始碼資料擷取工具，可讓您從各種來源收集資料、轉換資料並將資料傳送到所需目的地。憑藉預先建置的篩選條件和對 200 多個外掛程式的支援，Logstash 可讓使用者輕鬆擷取資料，而不管資料來源或類型如何。 架構: 一個輸入，一個輸出，中間有個管道（不是必須的），這個管道用來收集、解析和轉換日誌的。 three stages: inputs → filters → outputs Inputs generate events, filters modify them, and outputs ship them elsewhere. 簡介 Inputs, Filters 與 Outputs Inputs 如 file, syslog, redis or beat\n參考這篇 configure Filebeat to send log lines to Logstash Filters 如 grok, mutate, drop, clone, geoip\ngrok: 解析與重組文字，Logstash 中用來解析非結構性的 log 的最好方式，可參考這篇 mutate: 能夠 rename, remove, replace, and modify fields in your events drop: 完整剔除一個 event clone: 複製一個 event geoip: 加入一些新的資訊，如 IP 地址 Outputs 如 elasticsearch, file, graphite, statsd\nelasticsearch: 放在這邊的優點是效率、方便且容易搜尋的\nfile: 寫入檔案內\ngraphite: 一個 open-source 的儲存時序資料與 render graphs 工具\n根據官方文件介紹 Graphite does two things:\n1.Store numeric time-series data\n2.Render graphs of this data on demand\nstatsd:\n用途是監控應用程式，方式是將 metrics 收集、儲存並建立對應的警報機制 原理是監聽 UDP (或 TCP) 的程式並收集數據，將數據傳送給其他應用程式。 重要概念 bucket: 每個 stat 擁有自己的 bucket value: 每個 stat 擁有一個 value，通常是 integer type: 指定 c (用於計數器)、g (用於測量儀)、ms (用於計時器)、h (用於長條圖) 或 s (用於 set) 官方文件 Codecs plugins\n可在 input 或者 output 流程去更改數據顯示的格式 codec-plugins 整合多種 data source 參考這篇範例, conf 檔設定值應如下: input { twitter { consumer_key =\u0026gt; \u0026#34;enter_your_consumer_key_here\u0026#34; consumer_secret =\u0026gt; \u0026#34;enter_your_secret_here\u0026#34; keywords =\u0026gt; [\u0026#34;cloud\u0026#34;] oauth_token =\u0026gt; \u0026#34;enter_your_access_token_here\u0026#34; oauth_token_secret =\u0026gt; \u0026#34;enter_your_access_token_secret_here\u0026#34; } beats { port =\u0026gt; \u0026#34;5044\u0026#34; } } output { elasticsearch { hosts =\u0026gt; [\u0026#34;IP Address 1:port1\u0026#34;, \u0026#34;IP Address 2:port2\u0026#34;, \u0026#34;IP Address 3\u0026#34;] } file { path =\u0026gt; \u0026#34;/path/to/target/file\u0026#34; } } Kibana 一種用於檢視日誌和事件的資料視覺化和探索工具。Kibana 提供易於使用的互動式圖表、預先建置的彙總和篩選條件以及地理空間支援 Introduce 一種用於檢視日誌和事件的資料視覺化和探索工具。Kibana 提供易於使用的互動式圖表、預先建置的彙總和篩選條件以及地理空間支援 透過 kibana 能做到: 透過搜尋與觀察你的數據進而找出安全漏洞 分析與視覺化你的數據 管理數據、監測 Elastic Stack cluster 健康程度與權限控管 Kibana Query Language (KQL) only filters data, and has no role in aggregating, transforming, or sorting data filter documents where a value for a field exists, matches a given value, or is within a given range example filter for documents where the http.request.method is GET, use the following query:\nhttp.request.method: GET search for all documents for which http.response.bytes is less than 10000:\nhttp.response.bytes \u0026lt; 10000 filter documents where the http.request.method is not GET, use the following query:\n**NOT** http.request.method: GET find documents where a single value inside the user array contains a first name of “Alice” and last name of “White”, use the following:\nuser:{ first: \u0026#34;Alice\u0026#34; and last: \u0026#34;White\u0026#34; } Lucene query syntax regular expressions or fuzzy term matching Lucene syntax is not able to search nested objects or scripted fields. example find entries that have 4xx status codes and have an extension of php or html:\nstatus:[400 TO 499] AND (extension:php OR extension:html) Prometheus 介紹 open-source systems monitoring and alerting toolkit Cloud Native Computing Foundation (CNCF) in 2016 as the second hosted project NOTE: 第一個被 CNCF hosted 的 project 是 kubernetes collects and stores its metrics as time series data 優點 recording any purely numeric time series support for multi-dimensional data collection and querying Prometheus server is standalone, not depending on network storage or other remote services 缺點 不適合需要 100% accuracy 的服務 功能 a multi-dimensional data model with time series data identified by metric name and key/value pairs PromQL, a flexible query language to leverage this dimensionality no reliance on distributed storage; single server nodes are autonomous time series collection happens via a pull model over HTTP pushing time series is supported via an intermediary gateway targets are discovered via service discovery or static configuration multiple modes of graphing and dashboarding support metrics 介紹 metrics are numeric measurements Metrics play an important role in understanding why your application is working in a certain way. 支援四種 metrics types, 這篇有更詳細的介紹 Counter - only increase or reset\nGauge - 使用情境如計算 number of pods in a cluster, number of events in an queue\nHistogram - 使用情境可以是任何需要計算的值，如 API requests 所花費的時間，Histogram 會將數據存在 buckets 中，會先定義 buckets - lower or equal 0.3 , le 0.5, le 0.7, le 1, and le 1.2，接著計算完每次 request 所花費的時間後可以將對應到 bucket 的 count 加一，如下圖\nSummary - Histogram 的替代方案，因為更便宜，但付出的代價是 lose more data，原理是計算 metrics 的層級是 application level，所以當同一個 process 有諸多 instances 的話會無法計算\nComponents the main Prometheus server which scrapes and stores time series data client libraries for instrumenting application code a push gateway for supporting short-lived jobs special-purpose exporters for services like HAProxy, StatsD, Graphite, etc. an alertmanager to handle alerts various support tools Grafana 介紹 Grafana Labs 開發的 open-source 專案之一，還有其他專案，如 Grafana Loki (Like Prometheus, but for logs!), Grafana k6 (load testing tool)… query, visualize, alert on, and explore your metrics, logs, and traces wherever they are stored. 功能 Explore metrics, logs, and traces 以 RBAC ( Role-based access Control ) 來決定誰能夠 explore 這些數據 利用以下功能來查詢到更多數據趨勢與細節，細節參考這篇 query management in explore logs integration in explore trace integration in explore inspector in explore: 目的是 troubleshoot 你的 queries，可以將數據導出至 csv 檔案，logs 導出至 txt 檔案 Alerts 參考這篇去建立 alert rules，包含設定 threshold, interval, duration 「 缺少數據」也能被設定 alert 行為 Annotations Hover over events to see the full event metadata and tags. 參考這篇可進行 Add annotation, Add region annotation, Edit annotation, Delete annotation, Built-in query, Query by tag 等功能 Grafana provides many ways to authenticate users 預設是提供 password authentication，其他詳細請看這篇 參考資料 👐 what is elk stack Elasticsearch Service Documentation what-is-elasticsearch How Logstash Works | Logstash Reference [8.6] | Elastic elasticsearch introduction kibana introduction Overview | Prometheus Grafana documentation | Grafana documentation 🍀 若喜歡我的分享，可以幫我拍拍手👏，是對我最大的鼓勵\n","date":"2023-01-26T12:16:48+08:00","permalink":"https://yue-jenny.github.io/2023/01/%E7%B3%BB%E7%B5%B1%E8%A8%AD%E8%A8%88%E5%9F%BA%E7%A4%8E%E7%AD%86%E8%A8%98%E4%BA%94-logging-and-monitoring/","title":"系統設計基礎筆記(五) Logging And Monitoring"},{"content":"Kafka 最先是由 LinkedIn 創立的一款分散式訊息系統 (distributed messaging system)，由 Scala 和 Java 編寫的 open-source 專案 前言 Prerequistites Publish/Subscribe Pattern 📌 功能 高效能、容錯且具可擴展性的平台\n用於建置即時串流資料管道，並以 pub/sub pattern 來管理生產者與消費者的資料\nKafka Connect 是 Apache Kafka 的開放原始碼元件，是一個用於將 Apache Kafka 與外部系統 (如資料庫、機碼值存放區、搜尋索引和檔案系統) 連接的架構。 串流資料是一種小型記錄或事件 (記錄或事件通常為幾 KB 大小的記錄) 的持續串流，這類的記錄則由數千台機器、裝置、網站和應用程式所產生。串流資料包含各式各樣的資料，例如客戶使用您的行動或 Web 應用程式產生的日誌檔、電子商務採購、遊戲中的玩家活動、來自社交網路 資料取用的順序以 FIFO (First In First Out) 作為原則\n💫最重要的觀念💫 如何達到高效能、容錯且可擴展的呢?\npartition Partition 是最小的存儲單元 一個 Partition 內部消息有序，一個 Topic 跨 Partition 是無序的。 一個 Kafka cluster由多個 Broker（就是 Server） 構成，每個 Broker 中含有 cluster 的部分數據。\nPartition 分佈在多個 Broker 的話，Consumer 的多個實例就可以連接不同的 Broker 好處 Topic 就可以水平擴展 支持更多的 Consumer 一個 Consumer 實例負責一個 Partition 數據冗餘\n一個 Partition 生成多個副本，並且把它們分散在不同的 Broker。 如果一個 Broker 故障了，Consumer 可以在其他 Broker 上找到 Partition 的副本，繼續獲取消息。 寫入 Partition 的方式\n給 Kafka 決定 若沒有 key 則 kafka 以 round robin 方式將訊息寫入 partition，但這樣就不保證順序性了，若需要有順序性，請參考下面一個方式 使用 Partition Key 寫入特定 Partition kafka 保證使用相同的 key 會將訊息放到同一個 partition，並且保證順序性 ( in order ) 舉例，如果相同客戶的資訊有序地取得，表示需要放在同一個 partition，可以使用 customer id 作為 partition key，這樣同一個 customer 的資料都會放到同一個 partition 讀取 partition consumer group 多個 consumer 組合成一個 consumer group，目的是為了水平擴展(scale out) consumer 決定 consumer group 要從哪裡開始讀取資料的關鍵是 consumer offsets offsets 會被存在 topic name 中 如果 consumer 讀取資料完畢，則會 commit offsets apache zookeeper an open-source server which enables highly reliable distributed coordination 通過冗餘服務實現高可用性 參考資料 👐 Apache Kafka® 101: Partitioning 細說 Kafka Partition 分區 Apache Kafka vs Confluent: Comparing Features \u0026amp; Capabilities 全受管 Apache Kafka - Amazon MSK 常見問答集 - Amazon Web Services 🍀 最後，若喜歡我的分享，可以幫我拍拍手👏，是對我最大的鼓勵!✨\n","date":"2023-01-20T13:38:08+08:00","permalink":"https://yue-jenny.github.io/2023/01/kafka-%E7%B0%A1%E4%BB%8B/","title":"Kafka 簡介"},{"content":"Publish/Subscribe Pattern Publish/Subscribe Pattern (Pub/Sub) 簡介 一種包含 publisher、subscriber 與 broker 的訊息模型 publisher - 將訊息傳送至特定 topic(也可能被稱呼為 channels)，不需要擔心誰需要收到這筆消息 subscriber - 訂閱特定 topic 後，將會收到來自此 topic 的訊息 broker - 負責將 topic 的訊息轉發給 subscriber 通常有以下的保證，如「至少傳送一次」、「持久化」、「訊息的順序性」、「訊息可重送多次」 若相同訊息可重送多次，不會影響結果就是符合冪等性(idempotent)，需要 consumer 另外實作 有哪些 Pub/Sub 服務? 這邊舉幾個服務，後續再寫一篇較詳細文章來比較之間差異\nRabbitMQ 最廣泛使用的 message broker，特色是輕量級輕鬆部屬，但也有支援 distributed 以符合 high-scale 與 high-availability 的要求 點我看更多👀 Apache Kafka 最先是由 LinkedIn 創立的一款分散式訊息系統 (distributed messaging system)，由 Scala 和 Java 編寫的 open-source 專案，點我看更多👀 原本的 Kafka 團隊有出雲端受託管版本的 Kafka - Confluent Cloud (Cloud Native Apache Kafka®)，點我看更多👀 另外，AWS 也有是出自己的雲端版本的 Kafka - Amazon MSK，點我看更多 Cloud Pub/Sub Google 創立的雲端 Pub/Sub 服務，可用於串流服務、非同步微服務整合。點我看更多👀 參考資料 👐 system expert wiki - Kafka publisher-subscriber pattern 🍀 最後，若喜歡我的分享，可以幫我拍拍手👏，是對我最大的鼓勵!✨\n","date":"2023-01-18T20:13:18+08:00","permalink":"https://yue-jenny.github.io/2023/01/%E7%B3%BB%E7%B5%B1%E8%A8%AD%E8%A8%88%E5%9F%BA%E7%A4%8E%E7%AD%86%E8%A8%98%E5%9B%9B-publish/subscribe-pattern/","title":"系統設計基礎筆記(四) Publish/Subscribe Pattern"},{"content":"MapReduce 前言 MapReduce 是一個 Google 提出的軟體架構，適用於大規模資料的並列運算\nPrerequistites File System 資料的儲存系統 有許多不同型態，例如以垂直結構為主的目錄與資料夾、Object storage 等 Distributed File System 分散式檔案系統，透過一大群機器(cluster)互相合作，對外表現如同一個巨大的 file system，將 data 切成特定大小的 chunks (如 4 MB 或 64 MB)，會透過 central control plane 會決定應該將 chunks 存在哪一個 node，後續應該去哪一個 node 讀取 chunks 主要操作方式是透過網路以定義好的通訊協定進行資料存取 目前現有的產品有 Google File System (GFS)、Hadoop Distributed File System (HDFS) Hadoop 支持 MapReduce 與資料管線的 open-source 框架，最重要的中央組件為 Hadoop Distributed File System (HDFS) 各階段簡介 Map 階段 負責 filtering 和 sorting 並且組合出一個 key value pair 結果 Reduce 階段 負責資料整合 以 wordcount 為例，從 Map 傳過來的 key 若一樣，表示同一個字，因此把一樣的 key 做加總，可以得出最後的出總筆數 冪等性(idempotency)特性 意義: 當操作多次，結果應呈現一致 透過 pub/sub messaging system 應當有冪等性，因為 pub/sub 系統本身允許相同訊息被 consumer 接收多次 舉例，增加資料庫某欄位的 integer value，就不是一個具有冪等性的操作，因為保持每次增加的操作後都不會保持跟前一個相同的數值 另一舉例，將欄位值設定為 \u0026ldquo;DONE\u0026rdquo;，多次重複此操作，還是會顯示為 \u0026ldquo;DONE\u0026rdquo;，因此設定為 \u0026ldquo;DONE\u0026rdquo; 是一個冪等性操作 範例 input 要做計算的原始資料，可以是一堆文字清單等 split 把 input 資料做分散處理 以 hadoop 來說，當 MapReduce 工作被輸入的時候，會被切割到各個 cluster 裡面等待做處理 🔔map MapReduce 的 map 階段 每一個節點有自己的一份資料要分析，會把對應切割出來的資料建立 key value 的結果 key 是字本身，value 是 1 代表找到一筆 combine 在 map 的機器進行以下動作 將一樣的 key 先做一次加總，避免傳送多次出去，例如 combine 後的結果可能是 \u0026ldquo;A\u0026rdquo; 有 2 筆、\u0026ldquo;B\u0026rdquo; 有 1 筆等 shuffle \u0026amp; sort 在進入 reduce 階段之前，會先被做一個排序，因此相關的 key 會放在一起 比如第一批資料的 \u0026ldquo;A\u0026rdquo; 有 2 筆、第二批資料的 \u0026ldquo;A\u0026rdquo; 有 5 筆\u0026hellip;第一批資料的 \u0026ldquo;B\u0026rdquo; 有 1 筆、第二批資料的 \u0026ldquo;B\u0026rdquo; 有 3 筆 🔔reduce 此階段會做實際的加總，因此每一個 key 的 value 會被加總 output 最後得到的結果 參考資料 👐 system expert wiki MapReduce introduction-to-mapreduce 🍀 最後，若喜歡我的分享，可以幫我拍拍手👏，是對我最大的鼓勵!✨\n","date":"2023-01-18T10:32:40+08:00","permalink":"https://yue-jenny.github.io/2023/01/%E7%B3%BB%E7%B5%B1%E8%A8%AD%E8%A8%88%E5%9F%BA%E7%A4%8E%E7%AD%86%E8%A8%98%E4%B8%89-mapreduce/","title":"系統設計基礎筆記(三) MapReduce"},{"content":"Cache 快取 前言 快取對於系統層面上相當重要，用的好、用的巧，有助於整體系統的順暢度。\n因此目標是了解👉為什麼使用、👉使用策略與👉何時使用。\nPrerequistites cache 意思是將一部分的資料儲存起來，需要使用的時候，不需要經過後端或者資料庫再拿一次，優勢是取得資料較快 通常使用的情境是將常用且不經常修改的 response 儲存，不必每次都去跟後端與資料庫請求 cache hit 需要的資料能在快取中找到 🉐 cache miss 需要的資料無法在快取中找到 🈚 content delivery network (CDN) 一種第三方服務，扮演的角色就像快取，為什麼呢 ? 請往下看 越來越多服務的據點散布全球🌏，若 server 只有在幾個國家，其他國家的使用者可能會遇到網頁轉很久等問題⌛，中間網路傳輸耗時太長導致 latency 長，此時若有散布全球的 CDN server，請求就能先傳送到 CDN server 處理，縮短 latency 舉例一些 CDN 廠商，如 Cloudflare 與 Google cloud CDN 3 個使用快取的目的 利用前端快取，減少請求到後端 減少對資料庫的請求，降低資料庫壓力 避免 long compute operation，增加系統速度 快取更新機制 write through cache 同時更新資料庫與快取的資料 write back cache 先更新快取，再以非同步的方式更新資料庫的資料 快取替換機制 Cache eviction policy Least Recently Used (LRU) 依照最近使用時間來排序 思路: 最近使用時間最接近，表示近期內使用到的可能性也越高 優先替換掉最近使用時間距離當下最遠的那組數據 Least Frequently Used (LFU) 依照使用頻率來排序 思路: 使用次數越高⬆️，表示近期內使用到的可能性也越高⬆️ 優先替換掉使用次數最低的那組數據 First in First out (FIFO) 顧名思義，先進先出 思路: 最先進去快取的資料，越早會被淘汰 參考資料 👐 System expert 🍀 最後，若喜歡我的分享，可以幫我拍拍手👏，是對我最大的鼓勵!✨\n","date":"2023-01-17T11:04:46+08:00","permalink":"https://yue-jenny.github.io/2023/01/%E7%B3%BB%E7%B5%B1%E8%A8%AD%E8%A8%88%E5%9F%BA%E7%A4%8E%E7%AD%86%E8%A8%98%E4%BA%8C-cache/","title":"系統設計基礎筆記(二) Cache"},{"content":"Security And HTTPS 前言 除了了解前/後端語言與框架如何使用外，也希望能對 Http/Https 的原理與安全機制有所了解。\nPrerequistites IP Packet\n透過 IP 傳送的最小數據的單位，通常會包含 IP Header 與 payload IP Header 包含來源與目的地的 IP Address payload 就是你要傳送的資料 Man-In-The-Middle Attack (又稱呼為 MITM)\n意思是攔截 client 與 server 間傳送的訊息 💬 若 client 與 server 間傳送訊息有透過加密與 Https 可防止資料被竊取 Symmetric Encryption (對稱加密)\n加密與解密資料都使用同一把 key 🔑 缺點是安全性會有所疑慮，key 通常會被分享到一個點或多個點 優點是速度比非對稱加密快 🐇 最廣泛使用的演算法是 Advanced Ecryption Standard(AES) Asymmetric Encryption (非對稱加密)\n加密與解密資料會利用到兩把 key 🔑🔑，分別為 public key 與 private key public key 負責加密資料，只能利用相對應的 private key 解密資料 所以 public key 分享給需要加密資料的一端，而 private key 則需要 安全地保存 ㊙️ 速度會比對稱加密慢 🐢 Advanced Ecryption Standard(AES)\n最廣泛使用的加密標準 三種對稱演算法分別為 AES-128、AES-192、AES-256 Transport Layer Security (TLS)\n在傳輸層的一種協定，目的是為了網路通訊時的安全，確保沒有第三方能竊聽或者竊取任何資訊 衍生於另一種安全協定 Secure Socket Layer (SSL) SSL certificate\n由 certificate authority (CA) 頒發給 server 的數位憑證 內容包含 server 端的 public key，因為在 TLS Handshake 過程中會使用到 目的是確認 Http vs Https Http 全名為 HyperText Transfer Protocol 一種常見的網路通訊協議 流程是 client 送出 http request，而 server 送出回應 Https 全名為 HyperText Transfer Protocol Secure 顧名思義是為了可於網路上🔐安全地通訊而出現的一種網路通訊協議 為了達到上述要求，因此 server 被要求須具備以下兩項 須獲得可信任的憑證(SSL certificates) 使用 Transport Layer Security (TLS) 加密 client 與 server 端的數據。TLS 如何運作，請往下看。 TLS 連接是透過 TLS Handshake 來啟動 流程 client 送出 client hello (隨機的 bytes) 給 server server 回應 server hello (也是隨機的 bytes) 以及 SSL certificate client 驗證 CA 頒發的憑證，確認憑證正確屬於此 server 擁有 client 接著會送出一組用 public key 加密的 premaster secret 給 server client 和 server 將會使用 client hello, server hello與 premaster secret 產生對稱加密的 session keys，用於後續的通訊內容的加密與解密 🔐 TCP 利用 Handshake 方式來連接與斷連 TCP 三次握手(建立連線) 流程\n第一次握手： 客戶端傳送請求 SYN 報文給服務端，傳送完畢之後，客戶端處於 SYN_Send 狀態。 第二次握手： 服務端收到請求報文之後，如果同意連線，會回傳 SYN + ACK 應答報文，服務端為SYN_Receive狀態 第三次握手： 客戶端接收到服務端的 SYN + ACK ，然後傳送確認報文作為應答，客戶端轉為Established狀態 為什麼一定要三次?\n為了防止已失效的連接請求報文段突然又傳送到了服務端，因而產生錯誤 TCP 四次握手(結束連線) 流程 第一次分手 客戶端傳送FIN=1告訴服務端，客戶端所有的資料全部發送完畢，服務端可以關閉接收了。 第二次分手 服務端接收到客戶端的釋放請求連線之後，知道客戶端沒有資料傳送給自己了，然後服務端傳送ACK=1告訴客戶端接收到你發給我的訊息 第三次分手 告訴客戶端，服務端的所有資料傳送完畢，客戶端你也可以關閉接收資料連線了。 第四次分手 客戶端接收到了服務端傳送完畢的訊息之後，就傳送ACK=1，告訴服務端，客戶端已經接收到你的訊息 參考資料 👐 System expert what-happens-in-a-tls-handshake 🍀 最後，若喜歡我的分享，可以幫我拍拍手👏，是對我最大的鼓勵!✨\n","date":"2023-01-16T12:35:00+08:00","permalink":"https://yue-jenny.github.io/2023/01/%E7%B3%BB%E7%B5%B1%E8%A8%AD%E8%A8%88%E5%9F%BA%E7%A4%8E%E7%AD%86%E8%A8%98%E4%B8%80-security-and-https/","title":"系統設計基礎筆記(一) Security And HTTPS"},{"content":"如何設計與實作 Monorepo 的 Github Workflow? 前言 有鑑於越來越多人使用 monorepo，想研究一下，當只有針對某個 project 有程式碼的異動時，如何實踐 CI/CD\n什麼是 monorepo? 顧名思義，mono 表示一個，repo 表示 repository，也就是一個 repository 包含多個 projects，並且清楚定義它們之間的關係 例如前後端開發，將前後端的程式都放在同一個 repository，就是 monorepo 結構大致上會呈現如下圖，這次舉例有兩個 app 在同一個 repository 中 想知道必用的原因、好處或採坑紀錄，可先參考 👇 what-is-a-monorepo monorepo 之我見 如何設計 Github workflow? 參考Creating separate monorepo CI/CD pipelines with GitHub Actions，\n以 project 來區分 workflows 檔案，有 db.yaml、gateway.yaml 以及worker.yaml，如下圖\n當 gateway application 有程式碼異動，只能執行 gateway.yaml，測試或 build gateway image 等\n實作 Github Workflow YAML 檔案中是以 on 定義，哪些 events 可以去 trigger 一個 workflow，因此我們需要在這邊動一些手腳，讓他只有在異動特定 application 時才會執行 workflow\n利用 workflow syntax paths 指定範圍，當 pet app 底下的檔案有異動，執行這個 workflow\npaths: - \u0026#39;apps/pet/**\u0026#39; 如果想要再加入指定環境呢?比如指定 stage 或 main，可以利用 branches 的 workflow syntax\nbranches: [\u0026#39;stage\u0026#39;] 結合以上，整個看起來應該會像這樣，指定在 stage 的 pet app 有程式碼變化時，執行這個 workflow\non: push: branches: [\u0026#39;stage\u0026#39;] paths: - \u0026#39;apps/pet/**\u0026#39; 那如果是用 pull request 呢?\non: push: branches: [\u0026#39;stage\u0026#39;] paths: - \u0026#39;apps/pet/**\u0026#39; pull_request: branches: [\u0026#39;stage\u0026#39;] 我如何設計? 根據兩種環境 stage 與 main，以及兩種 app，總共會有 4 組 workflow yaml 檔案 stage-app1.yml stage-app2.yml main-app1.yml main-app1.yml 注意事項 ❗ \u0026ldquo;You must store workflow files in the .github/workflows directory of your repository.\u0026rdquo; Github Workflow 只支援第一層的 workflow yaml 檔案 也就是，以下圖的結構來放 workflow 檔案，Github 是不會執行的任何 workflow 的 官方文件說明 心得 經過這次，除了了解 monorepo 外，對於 Github Actions 的 Workflow syntax 更多的認識。\n參考資料 👐 Creating separate monorepo CI/CD pipelines with GitHub Actions what-is-a-monorepo monorepo 之我見 更多 workflow syntax 介紹 🍀 最後，若喜歡我的分享，可以免費幫我按讚，是對我最大的鼓勵! ✨ ✨ ✨\n","date":"2023-01-12T14:56:21+08:00","permalink":"https://yue-jenny.github.io/2023/01/%E5%A6%82%E4%BD%95%E8%A8%AD%E8%A8%88%E8%88%87%E5%AF%A6%E4%BD%9C-monorepo-%E7%9A%84-github-workflow/","title":"如何設計與實作 Monorepo 的 Github Workflow?"},{"content":"在 Argo CD 中使用 Github App Credential 作為驗證方式 前言 在先前文章使用 Docker Desktop 運行 Argo CD 以及在 Argo CD 內建立 App 偵測 repository 狀態 有提到 private repository 驗證的方式有 SSH、Https 以及 Github App Credential\n此文章來筆記下，如何在 Argo CD 中使用 Github App Credential 作為驗證方式\n實作 建立 Github App\n步驟可參考 👉 官方文件\n其中，特別需要設定的值\nGithub App Name: 為你的 Github App 取名稱\nHomepage URL: 你的 web app URL\n我的 argo cd 是以 docker desktop 啟動，並利用 port forward 方式，讓本地利用 localhost 可連線 dashboard，可參考我的文章使用 Docker Desktop 運行 Argo CD Callback URL: 當 github 認證完畢後，要 redirect 回去的 URL\n建立完成 Github App 後，還有兩件事情要做，Argo CD 設定連線時會用到\n查看 Github App Installation ID\n看 URL https://github.com/settings/installations/{Your Github App Installation ID}, 可確認 Github App Installation ID\n建立 private key\n到 Settings / Developer settings / Github Apps / {your-github-app-name} 的 General\n將頁面往下拉可以看見 Private keys，點 Generate a private key 建立一組 private key\n到 Argo CD 的 Repositories 設定連線資訊\n如何到這頁來設定，可參考官方文件\n這邊要填寫與設定的資訊分成兩部分\n先選到 VIA GITHUB APP\n依照上面的訊息完成填寫框 2的內容\n點 CONNECT，完成\n連線成功\n建立一組 NEW APP\n心得 看到官方提供驗證 private repository 的方式有 Github App Credential，讓我相當好奇，於是就有了這篇文章。\n後續再寫一篇文章來記錄 Github App 與 OAuth App差異。\n參考資料 👐 about-apps github-app-credential 🍀 「記錄」是為了有意識地、有條理地統整所學的學習知識。\n🍀 最後，若喜歡我的分享，可以免費幫我按讚，是對我最大的鼓勵! ✨ ✨ ✨\n","date":"2023-01-10T16:05:56+08:00","permalink":"https://yue-jenny.github.io/2023/01/%E5%9C%A8-argo-cd-%E4%B8%AD%E4%BD%BF%E7%94%A8-github-app-credential-%E4%BD%9C%E7%82%BA%E9%A9%97%E8%AD%89%E6%96%B9%E5%BC%8F/","title":"在 Argo CD 中使用 Github App Credential 作為驗證方式"},{"content":"Github 的 OAuth App 如何建立 OAuth App? 請參考 Creating an OAuth App - GitHub Docs Authorizing OAuth Apps Authorization flow 的分類 web application flow\nUsed to authorize users for standard OAuth apps that run in the browser. (The implicit grant type is not supported.) device flow\nUsed for headless apps, such as CLI tools. Web application flow 簡單 3 步驟可完成 👌 Users are redirected to request their GitHub identity\nUsers are redirected back to your site by GitHub\nYour app accesses the API with the user\u0026rsquo;s access token\n讓我們來詳細說說吧! Request a user\u0026rsquo;s GitHub identity\n利用 redirect 方式取得使用者的 GitHub identity，此時瀏覽器會跳出登入頁面讓使用者登入，需輸入帳密\n📌Request 方式如下\nRequired parameters client_id GET https://github.com/login/oauth/authorize Users are redirected back to your site by GitHub，接著請求 access token\n步驟一若成功完成驗證，則頁面會被返回至 App，接著要進行請求 access token 📌Request 方式如下 Required parameters client_id client_secret code，就是步驟一所帶的 state 欄位值 POST https://github.com/login/oauth/access_token 📌Response\n成功的話，你會取得一組 access token Accept: application/json { \u0026#34;access_token\u0026#34;:\u0026#34;gho_16C7e42F292c6912E7710c838347Ae178B4a\u0026#34;, \u0026#34;scope\u0026#34;:\u0026#34;repo,gist\u0026#34;, \u0026#34;token_type\u0026#34;:\u0026#34;bearer\u0026#34; } Use the access token to access the API\n利用步驟二的 access token 去 access API 📌這邊提供兩個 access API 的 request 方式 # 方式一 Authorization: Bearer OAUTH-TOKEN GET https://api.github.com/user # 方式二 curl -H \u0026#34;Authorization: Bearer OAUTH-TOKEN\u0026#34; https://api.github.com/user Device flow 目的: authorize users for a headless app, such as a CLI tool or Git credential manager. 簡單 3 步驟可完成 👌 Your app requests device and user verification codes and gets the authorization URL where the user will enter the user verification code.\nThe app prompts the user to enter a user verification code at https://github.com/login/device.\nThe app polls for the user authentication status. Once the user has authorized the device, the app will be able to make API calls with a new access token.\n讓我們來詳細說說吧! Step 1: App requests the device and user verification codes from GitHub\n📌Request\nRequired parameters client_id POST https://github.com/login/device/code 📌Response\n⚠️記下來 user code \u0026amp; verification uri，步驟二驗證時會使用到 ⚠️記下來 device code，步驟三驗證時會使用到 interval 意義是 minimum polling interval，單位為秒。 步驟三 app 會去 github poll (輪詢) user 是否已驗證完成此 device interval 即指 poll 的最小時間間隔。 若在 interval 內請求超過 1 次，則會到達 rate limit，會得到一些 error response，更詳細請看 👉 rate limits Accept: application/json { \u0026#34;device_code\u0026#34;: \u0026#34;3584d83530557fdd1f46af8289938c8ef79f9dc5\u0026#34;, \u0026#34;user_code\u0026#34;: \u0026#34;WDJB-MJHT\u0026#34;, \u0026#34;verification_uri\u0026#34;: \u0026#34;https://github.com/login/device\u0026#34;, \u0026#34;expires_in\u0026#34;: 900, \u0026#34;interval\u0026#34;: 5 } Step 2: Prompt the user to enter the user code in a browser\n📌利用步驟一得到 user code \u0026amp; verification uri (通常就是 https://github.com/login/device ) 📌到 https://github.com/login/device 輸入 user code Step 3: App polls GitHub to check if the user authorized the device\n📌Request\nRequired parameters 步驟一得到的 device code client id 指定的 grant type ⚠️注意: 發送輪詢請求，請求間隔必須大於最小輪詢時間間隔，否則會得到 error response，更詳細請看 👉 rate limits POST https://github.com/login/oauth/access_token 📌Response\n成功取得 access token Accept: application/json { \u0026#34;access_token\u0026#34;: \u0026#34;gho_16C7e42F292c6912E7710c838347Ae178B4a\u0026#34;, \u0026#34;token_type\u0026#34;: \u0026#34;bearer\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;repo,gist\u0026#34; } Rate limits ⚠️當達到 rate limits，會得到 slow_down 的 error response 📌更多 error response 請參考官方文件 📅 續集(二)會介紹 Non-Web application flow、Creating multiple tokens for OAuth Apps 以及 Directing users to review their access 參考資料 👐 OAuth Apps - GitHub Docs error-codes-for-the-device-flow web-application-flow - GitHub Docs Device flow - GitHub Docs Creating an OAuth App - GitHub Docs 🍀 最後，若喜歡我的分享，可以免費幫我按讚，是對我最大的鼓勵! ✨ ✨ ✨\n","date":"2023-01-07T18:10:13+08:00","permalink":"https://yue-jenny.github.io/2023/01/github-%E7%9A%84-oauth-app-%E4%BB%8B%E7%B4%B9-%E4%B8%80/","title":"Github 的 Oauth App 介紹 (一)"},{"content":"如何在 Hugo 中加入評論系統 Gitalk 前言 為了在部落格增加互動系統，選擇以 gitalk 作為 comment 系統\n實作 建立 Github OAuth App 並取得 client id \u0026amp; client secret (很重要，後續會用到)\n作法可參考官方文件 將資訊填入 themes\\hugo-theme-stack\\config.yaml\nclientID: 步驟一取得的 client id clientSecret: 步驟一取得的 client secret gitalk: owner: yue-jenny -\u0026gt; 你的 account name admin: yue-jenny -\u0026gt; 你的 account name repo: yue-jenny.github.io -\u0026gt; 你的 repo name clientID: 123 -\u0026gt; 步驟一取得的 client id clientSecret: 456 -\u0026gt; 步驟一取得的 client secret 上述步驟完成後，需要 admin (通常就是作者) 先 initial comment。\ninitial 完成後，頁面會這樣呈現。\nfinish-initial-comment 到 Github 可以看到，每一篇文章都會開一個 issue 紀錄，就像這樣。如果有留言，會在 issue 內多一個回應。\ngithub-issue-with-comment 關於 Github Oauth App 想知道更多，可參考 👉 這篇文章Github 的 Oauth App 介紹 (一) 參考資料 👐 creating-an-oauth-app 🍀 最後，若喜歡我的分享，可以免費幫我按讚，是對我最大的鼓勵! ✨ ✨ ✨\n","date":"2023-01-06T18:10:13+08:00","permalink":"https://yue-jenny.github.io/2023/01/%E5%A6%82%E4%BD%95%E5%9C%A8-hugo-%E4%B8%AD%E5%8A%A0%E5%85%A5%E8%A9%95%E8%AB%96%E7%B3%BB%E7%B5%B1-gitalk/","title":"如何在 Hugo 中加入評論系統 Gitalk"},{"content":"Argo CD 是什麼? 前言 這部分會分享 Argo CD 的中心思想、架構與功能。\nArgo CD 知識量很龐大，附上其他參考資料給有興趣的人參考\ngetting started guide user oriented documentation Developer oriented documentation the upgrade guide How it works? 🔩 GitOps pattern Argo CD follows the GitOps pattern of using Git repositories as the source of truth for defining the desired application state.\nArgo CD 遵循 GitOps 模式，即以 Git repositories 作為唯一識別 application 狀態的來源 kubernetes controller Argo CD 作為 kubernetes controller，持續偵測運行中的 application，並比較現在狀態與目標狀態\nArgo CD 的 kubernetes manifest 可用以下幾種方式建立:\nkustomize applications helm charts jsonnet files Plain directory of YAML/json manifests Any custom config management tool configured as a config management plugin architecture Argo CD architecture 架構圖 Components\nAPI Server\n可以被 Web UI, CLI, 以及 CI/CD systems 介接的 gRPC/REST server 它有幾項責任 應用管理與狀態回報 處理 application 的操作，如 sync, rollback, 其他使用者定義的動作 管理 credential，如 K8s secrets 管理驗證與權限 執行 RBAC Git webhook 事件的傾聽者/傳送者 Repository Server\n管理本地 Git repository 的快取 (Cache) 當有新增以下參數，需建立 Kubernetes manifests repository URL revision (commit, tag, branch) application path template specific settings: parameters, helm values.yaml Application Controller\n屬於 Kubernetes controller 👉 更多關於 Kubernetes controller 持續偵測運行中的 application，並比較現在狀態與目標狀態，若偵測到 OutOfSync 則會選擇性採取正確動作 此元件負責為生命週期事件(PreSync, Sync, PostSync)去調用使用者定義的 hooks Features 支援的功能繁多，列出一部分。每一版或者會有些不同，建議可參考 🔔 官方文件 🔔 自動部屬到特性目標環境 支援多種 templating 工具 (Kustomize, Helm, Jsonnet, plain-YAML) 能管理多種 clusters SSO 整合 (OIDC, OAuth2, LDAP, SAML 2.0, GitHub, GitLab, Microsoft, LinkedIn) 多租戶與 RBAC 政策 \u0026hellip;等 心得 💭 Argo CD 在 March 26, 2020 被 CNCF 列入，CNCF 的專案們整合程度越來越高，相信未來的多數公司的 CICD、監控、Log、角色權限控管、資料庫等會以 CNCF 專案為主。\n若想知道如何在 docker desktop 建立 Argo CD，請參考文章 👉 使用 Docker Desktop 運行 Argo CD\n參考資料 👐 Argo CD Argo CD Components Kubernetes Controllers 🍀 最後，若喜歡我的分享，可以免費幫我按讚，是對我最大的鼓勵! ✨ ✨ ✨\n","date":"2023-01-05T10:56:11+08:00","permalink":"https://yue-jenny.github.io/2023/01/argo-cd-%E6%98%AF%E4%BB%80%E9%BA%BC/","title":"Argo CD 是什麼?"},{"content":"Prerequisites 開始前，需要先確保有以下的先備知識\nkubernetes Argo CD 介紹 以 GitOps 模式為宗旨的持續部屬 (continuous delivery) 工具 關於 GitOps 可以參考文章 GitOps Getting Started with Argo CD on Docker Desktop 讓我們一步一步開始吧! 💪\n建立 namespace kubectl create namespace argocd 安裝 Argo CD 的 kubernetes resources 需要安裝的 resources 都寫在 install.yaml 內，利用 kubectl apply 指令進行安裝\nkubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml 確認 Argo CD 的 pod 的運行狀態為 running -n 表示指定 namespace 為 argocd，沒設定就是 default namespace\nkubectl get pod -n argocd pod 運行狀態\n取得 Argo CD 初始 admin 的密碼 登入 dashboard 使用\nkubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath=\u0026#34;{.data.password}\u0026#34; | base64 -d; echo 將 service argocd-server port forward 到本地 將 service argocd-server 的 port 443 導至本地 port 8000\nkubectl port-forward svc/argocd-server -n argocd 8000:443 port forward 成功\n登入 Argo CD dashboard 網址輸入 https://localhost:8000\n成功登入 Argo CD dashboard\n針對 public git repository 建立一組 application 先 fork 範例 repository - argocd-example-apps\n依照官方文件指示步驟進行新增 application\nStep 1 Step 2，填完資訊，按下 CREATE，能在 dashboard 看到 application\napp name: guestbook project: default sync policy: Manual Repository URL Revision: HEAD Path: guestbook Destination/Cluster: https://kubernetes.default.svc Namespace: default 針對 private git repository 建立一組 application 選一組 private repo\n到 Settings/Repositories\n以 ssh-key 方式認證，也能選擇以 Https或者 Github App 的方式驗證\n可參考Argo CD Private Repositories Credential 設定 可參考我的文章使用 Github App Credential 認證 設定完成會顯示 Successful 建立 application\nStep 1 Step 2\n依照官方文件指示步驟填入資料 成功建立一組 private application 🚀\n解除安裝 application 執行 DELETE 按鈕\n解除安裝 Argo CD ⚠️ 解除安裝 Argo CD 前一定要先解除安裝 application\nkubectl -n argocd delete -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml 遇過的問題 參考資料 Argo CD Argo CD getting started 參考文件 kubernetes kubectl port-forward Argo CD Private Repositories Credential 設定 🍀 最後，若喜歡我的分享，可以免費幫我按讚，是對我最大的鼓勵! ✨ ✨ ✨\n","date":"2023-01-04T04:39:13.628Z","permalink":"https://yue-jenny.github.io/2023/01/%E4%BD%BF%E7%94%A8-docker-desktop-%E9%81%8B%E8%A1%8C-argo-cd-%E4%BB%A5%E5%8F%8A%E5%9C%A8-argo-cd-%E5%85%A7%E5%BB%BA%E7%AB%8B-app-%E5%81%B5%E6%B8%AC-repository-%E7%8B%80%E6%85%8B/","title":"使用 Docker Desktop 運行 Argo CD 以及在 Argo CD 內建立 App 偵測 repository 狀態"},{"content":"OpenID Connect (OIDC) 介紹 前言 OIDC 全名為 OpenID Connect，是一種可以 access AWS resources，但不需要存取 AWS credentials 當作 long-lived GitHub secrets 的驗證方式。 官方建議的驗證方式。 OIDC 優點 - 很好的安全實踐 (good security practices) No cloud secrets 不需要以 cloud credentials 當作 long-lived GitHub secrets 在 cloud provider 設定好 OIDC trust，github workflows 就可以利用 OIDC 從 cloud provider 取得一組 short-lived access token Authentication and authorization management 透過 cloud provider 的 authentication (authN) 與 authorization (authZ) 工具能夠控制取得 cloud resources 能更小粒度地控制 workflows 如何使用 credentials Rotating credentials cloud provider 提供一組 short-lived access token 給一個 job，使用完畢後會自動過期。 OIDC 的運作方式與信任機制 運作方式 主要是兩個角色的互動，分別為 Cloud Provider 與 Github OIDC Provider 互動過程 : In your cloud provider, create an OIDC trust between your cloud role and your GitHub workflow(s) that need access to the cloud. Every time your job runs, GitHub\u0026rsquo;s OIDC Provider auto-generates an OIDC token. This token contains multiple claims to establish a security-hardened and verifiable identity about the specific workflow that is trying to authenticate. You could include a step or action in your job to request this token from GitHub\u0026rsquo;s OIDC provider, and present it to the cloud provider. Once the cloud provider successfully validates the claims presented in the token, it then provides a short-lived cloud access token that is available only for the duration of the job. 可參考官方文件 安全 - OIDC trust 當設定 cloud 能信任 GitHub\u0026rsquo;s OIDC provider 後，必須加上一些情境去過濾掉 requests，避免沒有取得信任的 repositories or workflows 可以透過 access token 操作你的 cloud resources。 Configuring OpenID Connect in Amazon Web Services 前言 目的是 Use OpenID Connect within your workflows to authenticate with Amazon Web Services. 官方文件 IAM Role 1. Create a iam role 建立一組 iam role，用於上傳 docker image 到 private ECR 建立 iam role 的時候，會需要填入以下資訊 : provider URL : https://token.actions.githubusercontent.com Audience : sts.amazonaws.com 2. Permissions policies iam role 綁定的 permissions policies 是 AmazonEC2ContainerRegistryPowerUser 此政策允許委託人讀取和寫入儲存庫，以及讀取生命週期政策。委託人不會被授予刪除儲存庫或變更套用至其生命週期政策的許可。 可依據需求設定不同的 permissons policies，可參考官方文件 3. Add the GitHub OIDC provider to IAM Configure the role and trust in IAM.\n到 iam role 頁面點選編輯 Trust relationships\n參考以下的方式將 sub 欄位加入到 Condition 中\n方式一，使用 StringLike\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Federated\u0026#34;: \u0026#34;arn:aws:iam::123456123456:oidc-provider/token.actions.githubusercontent.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRoleWithWebIdentity\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringLike\u0026#34;: { \u0026#34;token.actions.githubusercontent.com:sub\u0026#34;: \u0026#34;repo:octo-org/octo-repo:*\u0026#34; }, \u0026#34;StringEquals\u0026#34;: { \u0026#34;token.actions.githubusercontent.com:aud\u0026#34;: \u0026#34;sts.amazonaws.com\u0026#34; } } } ] } 方式二，使用 StringEquals\n\u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;token.actions.githubusercontent.com:aud\u0026#34;: \u0026#34;sts.amazonaws.com\u0026#34;, \u0026#34;token.actions.githubusercontent.com:sub\u0026#34;: \u0026#34;repo:octo-org/octo-repo:ref:refs/heads/octo-branch\u0026#34; } } 官方文件\nUpdating your GitHub Actions workflow 上述是 AWS 相關設定，此步驟是調整 github workflow，做兩件事情 :\nAdding permissions settings，有兩種權限選擇，可依照自身情境去選擇。\nfetch an OIDC token for a workflow, then the permission can be set at the workflow level.\npermissions: id-token: write # This is required for requesting the JWT contents: read # This is required for actions/checkout only need to fetch an OIDC token for a single job\npermissions: id-token: write # This is required for requesting the JWT Use the aws-actions/configure-aws-credentials action\n此 action 會接收來自 GitHub OIDC provider 的 JWT，並且向 AWS 請求一組 access token - name: Configure AWS credentials uses: aws-actions/configure-aws-credentials@v1 with: role-to-assume: arn:aws:iam::1234567890:role/example-role role-session-name: GitHubActionsWithAwsEcrUsingOIDCSession aws-region: ${{env.AWS_DEFAULT_REGION}} 參考資料 configuring-openid-connect-in-amazon-web-services about-security-hardening-with-openid-connect 最後，若喜歡我的分享，可以免費幫我按讚，是對我最大的鼓勵!\n","date":"2022-12-29T14:32:24+08:00","permalink":"https://yue-jenny.github.io/2022/12/%E5%9C%A8-github-workflow-%E4%B8%AD%E4%BD%BF%E7%94%A8-openid-connect-oidc-%E5%8E%BB%E8%AA%8D%E8%AD%89-aws-%E6%9C%8D%E5%8B%99/","title":"在 Github workflow 中使用 OpenID Connect (OIDC) 去認證 AWS 服務"},{"content":"Github Workflow 介紹 前言 為了利用 Github Workflow 完成 CI/CD，分成幾個部分來寫，分別是\nGithub Workflow 的基本設定 Github Workflow 中進行 CI 登入登出 AWS ECR 與 github container registry build \u0026amp; upload image 更新 helm value 中的 image tag，後續讓 argocd 得以偵測到 helm values 的變化後，進行自動化部屬 基本設定 action 為 push 的時候，所有 branch 都會進行 github workflow action 為 pull_request 的時候，只有 main branch 會進行 github workflow types paths on: push: branches: [\u0026#34;*\u0026#34;] pull_request: branches: [\u0026#34;main\u0026#34;] types: - opened paths: - \u0026#34;**.js\u0026#34; env 設定 設定方式如下，可以依照自身需求進行設定 env: AWS_DEFAULT_REGION: ap-southeast-1 GIT_USER_NAME: jennyc permissions 設定 設定方式如下，可以依照自身需求進行設定 permissions: id-token: write # This is required for requesting the JWT contents: read # This is required for actions/checkout 自動化測試 CI checkout repository 使用 actions/checkout@v3 進行\n- name: Checkout repository uses: actions/checkout@v3 執行 npm install - name: Install dependencies run: npm install 執行 npm test - name: Run tests run: npm run test Build multi-platform images 並上傳至 AWS ECR 前言 這部分需要先設定 AWS Credential 才能使用 AWS ECR，\n接著 build multi-platform image 並且上傳至 AWS ECR。\n1. 設定 AWS Credential 設定 AWS Credential\n使用 GitHub\u0026rsquo;s OIDC provider 方式取得 short-lived credentials\nOpenID Connect (OIDC) 設定方式可以參考官方文件 也可以參考這篇文章 workflow 要怎麼寫?\nenv.AWS_DEFAULT_REGION 需要特別設定，與 AWS ECR 相同的 region role-to-assume 填入 AWS role role-session-name 預設是 GitHubActions，可以自行調整名稱 - name: Configure AWS credentials uses: aws-actions/configure-aws-credentials@v1 with: role-to-assume: arn:aws:iam::1234567890:role/example-role role-session-name: GitHubActionsWithAwsEcrUsingOIDCSession aws-region: ${{env.AWS_DEFAULT_REGION}} 2. 登入 AWS private ECR 有兩種方式 Using access key id and secret access key to login\n- name: Configure AWS credentials uses: aws-actions/configure-aws-credentials@v1 with: aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }} aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }} aws-region: ap-southeast-1 Using OpenID Connect (OIDC) to login\n官方推薦使用此方式 - name: Login to Amazon ECR id: login-ecr uses: aws-actions/amazon-ecr-login@v1 3. 登入 AWS public ECR 可參考官方說明 4. 登出 AWS ECR - name: Logout of Amazon ECR if: always() run: docker logout ${{ steps.login-ecr.outputs.registry }} 5. 設定 short sha 為 image tag 設定以 7 digits 長度的 short sha 作為 image tag，原因可以參考: 7 digits are the Git default for a short SHA 附上其他參考文件 Chapter 7 of the Pro Git book 將 output 出去的參數命名為 sha_short - name: Set short sha outputs id: vars run: echo \u0026#34;sha_short=$(git rev-parse --short HEAD)\u0026#34; \u0026gt;\u0026gt; $GITHUB_OUTPUT 6. Build multi-platform images 並上傳 images 到 AWS ECR 建立多平台 docker images 的官方文件 IMAGE_TAG 會從步驟 5 取得 output 的變數 sha_short --platform 可接上需要的 platform 參考，例如 linux/amd64, linux/arm64 - name: Build, tag, and push docker image to Amazon ECR env: REGISTRY: ${{ steps.login-ecr.outputs.registry }} REPOSITORY: pet-app IMAGE_TAG: ${{ steps.vars.outputs.sha_short }} run: | docker run --rm --privileged multiarch/qemu-user-static --reset -p yes ( 官方建議: docker run --privileged --rm tonistiigi/binfmt --install all ) docker buildx create --name mybuilder --driver docker-container --bootstrap docker buildx use mybuilder docker buildx inspect docker buildx build --platform linux/amd64,linux/arm64 -t $REGISTRY/$REPOSITORY:$IMAGE_TAG --push . 為什麼需要 docker run --rm --privileged multiarch/qemu-user-static --reset -p yes ?\n因為遇到 Error: while loading /usr/local/sbin/node: No such file or directory 問題 先使用方式一 : 連接方式，結果還是有相同問題 ln -s /usr/bin/node /usr/local/sbin/node 後來使用方式二 使用 docker buildx 指令前先執行以下命令\ndocker run --rm --privileged multiarch/qemu-user-static --reset -p yes 詳細原因的 Stack Overflow 原始文章在這邊，以下是節錄部分\n` When you ask the Linux kernel to run some executable file, it needs to know, how to load this specific file, and whether this file is compatible with current machine, or not. By default, the ELF binary compiled for, say, arm64v8 is rejected by the kernel, running on amd64 hardware.\nHowever, the binfmt_misc feature of the kernel allows you to tell it, how to handle the executables it cannot usually handle on its own - this includes the cases when the kernel does not know the binary format or considers it incompatible with current machine.\n`\ngithub issue\n官方建議使用以下命令解決 QEMU binaries 問題，官方文件\ndocker run --privileged --rm tonistiigi/binfmt --install all 更新 helm value 的 image tag 前言 應用是以 terraform 方式部屬，並搭配使用 helm charts。而 docker image 的 tag 是寫在 helm values 內。\n目標是更新 helm values 的 docker image tag 值，後續讓 argocd 得以偵測到 helm values 的變化後，進行自動化部屬。\n需做到兩件事情:\ncheckout 私有 repository 設定與更新 image tag 1. 先 checkout 私有存放 helm value 的 repository 需要先設定 credential 才能 fetch private repository，有兩種設定的方式\n設定 deploy key\n步驟如下，可參考這篇\nCreate a new SSH key pair for your repository. Do not set a passphrase. Copy the contents of the public key (.pub file) to a new repository deploy key and check the box to \u0026ldquo;Allow write access.\u0026rdquo; Add a secret to the repository containing the entire contents of the private key. As shown in the example below, configure actions/checkout to use the deploy key you have created. workflow 要怎麼寫?\nssh-key 填入 private key 的 secrets 名稱 path 設定 checkout 的 repo 會存在哪一個資料夾內 - name: Checkout ${{env.TERRAFORM_REPOSITORY_NAME}} repo and push file to ${{env.TERRAFORM_REPOSITORY_NAME}} uses: actions/checkout@v3 with: repository: ${{env.TERRAFORM_REPOSITORY_OWNER_NAME}}/${{env.TERRAFORM_REPOSITORY_NAME}} ssh-key: ${{ secrets.SSH_PRIVATE_KEY }} path: ${{env.TERRAFORM_REPOSITORY_NAME}} 設定 Personal access token (PAT)\n建立 PAT 的方式，官方文件\n將建立完成的 PAT 設定到 repository 的 secrets 中，設定的 secrets 名稱為 GH_PAT，官方文件\nworkflow 要怎麼寫?\nrepository 設定為 owner/repository_name token 填入 PAT 的 secrets 名稱，這邊是將 secrets 名稱為 GH_PAT 的內容設定為 PAT - name: Checkout ${{env.TERRAFORM_REPOSITORY_NAME}} repo and push file to ${{env.TERRAFORM_REPOSITORY_NAME}} uses: actions/checkout@v3 with: repository: ${{env.TERRAFORM_REPOSITORY_OWNER_NAME}}/${{env.TERRAFORM_REPOSITORY_NAME}} token: ${{ secrets.GH_PAT }} 2. 設定 image tag 設定以 7 digits 長度的 short sha 作為 image tag 7 digits are the Git default for a short SHA 附上其他參考文件 Chapter 7 of the Pro Git book - name: Set short sha outputs id: vars run: echo \u0026#34;sha_short=$(git rev-parse --short HEAD)\u0026#34; \u0026gt;\u0026gt; $GITHUB_OUTPUT 3. 更新 image tag 以 yq 的 github action 工具修改 yaml 檔內的 image tag 值 yq 的官方文件 yq 的 github 進行 git 操作，設定 user name, user email、commit 以及 push tag 取上一個步驟 output 的參數 sha_short - name: Update image tag uses: mikefarah/yq@master with: cmd: yq -i \u0026#39;.pet_app_dashboard_site.image.tag = \u0026#34;${{ steps.vars.outputs.sha_short }}\u0026#34;\u0026#39; ./${{env.TERRAFORM_REPOSITORY_NAME}}/${{env.HELM_FILE_NAME}} - run: | cd ${{env.TERRAFORM_REPOSITORY_NAME}} git config user.name ${{env.GIT_USER_NAME}} git config user.email ${{env.GIT_USER_EMAIL}} git add ${{env.HELM_FILE_NAME}} git commit -m \u0026#34;update image tag to ${{ steps.vars.outputs.sha_short }}\u0026#34; git push origin main 若要將 docker image 上傳至 github container registry 該怎麼做? 1. 登入與登出 github container registry 需要設定 env.REGISTRY 為 ghcr.io\n不需要另外設定 github.actor 與 GITHUB_TOKEN\n- name: Login to GitHub Container Registry uses: docker/login-action@v2 with: registry: ${{ env.REGISTRY }} username: ${{ github.actor }} password: ${{ secrets.GITHUB_TOKEN }} 2. Extract metadata - name: Extract metadata (tags, labels) for Docker id: meta uses: docker/metadata-action@98669ae865ea3cffbcbaa878cf57c20bbf1c6c38 with: images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }} 3. Build and push docker image labels 的值可以從步驟二取出 outputs labels 來使用 - name: Build and push Docker image uses: docker/build-push-action@ad44023a93711e3deb337508980b4b5e9bcdc5dc with: context: . push: true tags: ${{ env.REGISTRY }}/${{ env.REPO }}:${{ steps.vars.outputs.sha_short }} labels: ${{ steps.meta.outputs.labels }} 參考資料 actions/checkout amazon-ecr-login docker/login-action docker-build-fails-for-arm-images yq 的官方文件 yq 的 github Chapter 7 of the Pro Git book creating-a-personal-access-token creating-and-using-encrypted-secrets 最後，若喜歡我的分享，可以免費幫我按讚，是對我最大的鼓勵!\n","date":"2022-12-10T18:33:05+08:00","permalink":"https://yue-jenny.github.io/2022/12/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8-github-workflow-%E5%AE%8C%E6%88%90-ci/cd/","title":"如何使用 Github Workflow 完成 CI/CD"},{"content":"如何用 github pages host 靜態檔案? 讓我們一步一步開始吧! 💪\n1. Create a repository 2. Naming repository name 將 repository 依據模板 username.github.io 命名 ⚠️ username 是帳戶名稱 查看自己的 URL 可以查出 username，依據模板 https://github.com/YOUR_USERNAME 呈現 我帳戶名稱是 Yue-Jenny，username 需設定為 yue-jenny 3. 上傳你的靜態檔案到 github 參考\u0026quot;為什麼我決定使用 hugo 建立一個 blog 系統 📙，以及我該如何建立?\u0026quot;，用 hugo 建立你的部落格系統，並將 publishing directory 的靜態檔案上傳到 github repository 4. 設定 到 repository 的 Settings 頁籤\n\u0026ldquo;Code and automation\u0026rdquo; 區塊中點選 Pages\n\u0026ldquo;Source\u0026rdquo; 選 Deploy from a branch\n\u0026ldquo;Branch\u0026rdquo; 選 publishing 的來源\n\u0026ldquo;為什麼我決定使用 hugo 建立一個 blog 系統 📙，以及我該如何建立?\u0026rdquo; 設定 publishing directory 為 docs，所以選 docs 5. 拜訪你的新網站 🔥 瀏覽器輸入 URL username.github.io\n參考資料 github pages quickstart 最後，若喜歡我的分享，可以免費幫我按讚，是對我最大的鼓勵!\n","date":"2022-12-10T18:25:43+08:00","permalink":"https://yue-jenny.github.io/2022/12/%E5%A6%82%E4%BD%95%E7%94%A8-github-pages-host-%E9%9D%9C%E6%85%8B%E6%AA%94%E6%A1%88/","title":"如何用 github pages host 靜態檔案?"},{"content":"為什麼我決定使用 Hugo \u0026amp; Github pages 建立一個 blog 系統? 1. 內容保存與控管 ✅ 文章內容以 markdown 語法撰寫與保存，熟悉 markdown 語法後，會發現很方便 👍 推薦使用 vscode 作為編輯器 ☝️ 加入 extension 可確認 markdown 內容呈現 ✌️ 直接執行指令運行網站 ✅ 內容可定期放上雲端保存備份，不用擔心若部落格系統下線後，文章也跟著消失或者該如何備份 ✅ 修改內容時，不怕線上部落格系統出現問題，輸入到一半的內容直接消失 ( 曾經有類似的經驗，全部重來 😓) 2. 可高度客製化 ✅ 客製字體大小顏色、主題套件等 UI 的部分 ✅ 自由決定要加入哪些功能，建立擁有自我風格的部落格系統 💪 評論區(支援不同多種軟體) LikeCoin button Table of contents 頁首與頁尾設計 \u0026hellip; etc Hugo \u0026amp; Github pages 基本知識 1. Hugo 介紹 引用自官方文件說明 Hugo is a fast and modern static site generator written in Go, and designed to make website creation fun again.\n2. Github pages 介紹 引用自官方文件說明 You can use GitHub Pages to showcase some open source projects, host a blog, or even share your résumé. This guide will help get you started on creating your next website.\nGetting start，讓我們進入正題吧! 基本功能 1. Prerequisites\nInstall Hugo，安裝能夠 compile go language 的工具，不同 OS 安裝不同的檔案 Install Git，後續下載 theme 使用 2. Create a site\nhugo new site quickstart 3. 到 quickstart 目錄，並執行 initial git repository\ncd quickstart git init 4. clone ananke theme，並以 git submodule 方式存在\n若想了解 git submodule，可參考官方文件\ngit submodule add https://github.com/theNewDynamic/gohugo-theme-ananke themes/ananke 5. 設定 site configuration file\n在 config.toml 加入這行\ntheme = \u0026#39;ananke\u0026#39; 6. 本地啟動 hugo 專案\n本地啟動 hugo 專案，-p 是指定 port 為 8080\n想知道更多 hugo 命令行可以點這邊\nhugo server -p 8080 瀏覽器輸入 https://localhost:8080，可確認頁面已出現 (這時還沒有文章內容)\n7. 開始寫文章\n建立一個 markdown 檔案，markdown 檔案內的設定的意義\ntitle - 文章標題 date - 建立此文章的時間，文章會跟著時間排序 draft - 是否為草稿，production 環境建議只顯示非草稿的文章，寫完文章可改為 false，再執行 build 指令，讓 markdown 變成 html 等靜態檔案。 hugo new content/post/oidc-aws/index.md 8. 運行網站\n寫完文章內容後 ✏️，設定 markdown 檔案內的 draft 為 false，表示非 draft 模式，重刷頁面可看到文章\n若需要在 draft 模式下顯示文章，需調整啟動 server 的命令行\n-D表示 --buildDrafts，會包含註記為 draft 的內容 hugo server -D -p 8080 成功 🚀 🚀 🚀 9. host on github page\n設定 github pages，請參考 如何用 github pages host 靜態檔案 基本客製化功能 hugo 提供一些客製化功能，來看看應該怎麼做?\n如何設定 publish 資料夾? 在 config.toml 中加入以下設定，能將 publish 資料夾設定為 docs，而 Github pages 能 host docs 資料夾內的靜態檔案\npublishDir = \u0026#34;docs\u0026#34; 如何替換成不同 theme? 我使用的主題是 hugo-theme-stack ( 官方文件 )，該如何調整?\nclone hugo-theme-stack theme git submodule add https://github.com/CaiJimmy/hugo-theme-stack themes/hugo-theme-stack 調整 config.toml 的設定值 theme theme = \u0026#39;hugo-theme-stack\u0026#39; 如何客製化文章中的 font family? 調整 themes\\hugo-theme-stack\\layouts\\partials\\head\\custom.html ，內容如下\n以 google fonts 作為字體來源、以 css2 作為樣式來源 \u0026lt;style\u0026gt; :root { --article-font-family: \u0026#34;Literata\u0026#34;, var(--base-font-family); } \u0026lt;/style\u0026gt; \u0026lt;script\u0026gt; (function () { const customFont = document.createElement(\u0026#39;link\u0026#39;); customFont.href = \u0026#34;https://fonts.googleapis.com/css2?family=Literata:wght@400;700\u0026amp;display=swap\u0026#34;; customFont.type = \u0026#34;text/css\u0026#34;; customFont.rel = \u0026#34;stylesheet\u0026#34;; document.head.appendChild(customFont); }()); \u0026lt;/script\u0026gt; 參考官方文件\n如何客製化建立 index.md 的模板? 調整 archetypes\\default.md 有其他更進階的用法，請參考官方文件 進階客製化 ☝️ 如何在 Hugo 的文章中加入 LikeCoin button? LikeCoin 是強調內容有價的而出現的虛擬貨幣，可給作者支持與鼓勵 實作方式: 註冊 Liker ID\n建立 themes\\hugo-theme-stack\\layouts\\partials\\likecoin.html\n\u0026lt;iframe class=\u0026#34;LikeCoin\u0026#34; height=\u0026#34;235\u0026#34; src=\u0026#34;https://button.like.co/in/embed/{{ .Site.Params.likerID }}/button?referrer={{ .Permalink }}\u0026#34; width=\u0026#34;100%\u0026#34; frameborder=0\u0026gt;\u0026lt;/iframe\u0026gt; 在 config.toml 中加入以下程式碼，並將 [LikerID] 更改為你的 Liker ID\n[Params] likerID = \u0026#34;YOUR_LIKERID\u0026#34; 在文章的模板中加入 LikeCoin button\n將以下的程式碼填入 themes\\hugo-theme-stack\\layouts\\partials\\article\\article.html 中\n{{ partial \u0026#34;likecoin.html\u0026#34; . }} 官方文件 進階客製化 ✌️ 如何使用 Google Console Search 偵測網站的收錄情況? 藉由了解網站成效，並針對弱點進行優化，可增加網站的曝光率 🌟 進階客製化 👌 SEO 搜尋引擎優化 google 會依據網頁網址建立 index，搜尋結果會先呈現有建立 index 的網頁 因此為了強化網頁的 SEO，將你建立 sitemap 交給 google ，讓 google 搜尋可快速找到你的網頁 注意事項 ⚠️ 執行完 build 指令後，建議習慣檢查 docs 資料夾 ( 或你的 publish 資料夾 ) 內的 html 變化是否符合預期\n心得 這應該是第二次使用 framework 方式建立靜態文件系統，第一次是使用 vuepress 協助公司建立內部文件系統，這次是使用 hugo。前者是以 javascript 為當作開發語言，後者是以 go 為開發語言。兩者都蠻推薦。 最重要的是了解該框架是如何運行的，在高度客製化功能或者修改問題的時侯才不會瞎子摸象般的亂試。 hugo 有 64.5k 🌟 (截止至 20230103)，很多人持續貢獻與維護 🙏 ，因此軟體工程師從頭到尾依靠官方文件與 google 完成基本建立不難。 參考資料 github pages quickstart hugo documentation self host likecoin button css2 fifty of the most popular hugo themes / hugo 熱門主題大公開 Build and submit a sitemap to google ","date":"2022-12-10T18:22:43+08:00","permalink":"https://yue-jenny.github.io/2022/12/%E7%82%BA%E4%BB%80%E9%BA%BC%E6%88%91%E6%B1%BA%E5%AE%9A%E4%BD%BF%E7%94%A8-hugo-%E5%BB%BA%E7%AB%8B%E4%B8%80%E5%80%8B-blog-%E7%B3%BB%E7%B5%B1-%E4%BB%A5%E5%8F%8A%E6%88%91%E8%A9%B2%E5%A6%82%E4%BD%95%E5%BB%BA%E7%AB%8B/","title":"為什麼我決定使用 hugo 建立一個 blog 系統 📙，以及我該如何建立?"}]